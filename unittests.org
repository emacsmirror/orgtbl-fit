* GPL-3 Licence
#+TITLE: Unit Tests & Examples for Orgtbl Fit
Copyright (C) 2021-2025  Thierry Banel

orgtbl-fit is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

orgtbl-fit is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.

* Recipe to run unit tests
To run unit tests:
- Execute the following Lisp block by typing ~C-c C-c~ in it.
- Look at the differences between this reference unittests.org file
  and the disposable buffer.
  The first difference is where the cursor is.
- If all tests were successful, the cursor is at the end of the file.

#+begin_src elisp :results none
(delete-other-windows)
(goto-char (point-min))
(org-cycle '(64))
(split-window-right)

;; Make a new buffer and fill it with the content of unittests.org

(let ((f (buffer-file-name)))
  (switch-to-buffer "disposable-unittest.org")
  (erase-buffer)
  (insert-file f))

(org-mode)
(org-cycle '(64))

;; Iterate over each unit test
(let (model c)
  (while
      (and
       (search-forward-regexp
	(rx bol "model" (* space) "=" (* space) (group (+ nonl)))
	(point-max)
	t)
       (setq model (match-string 1))
       (search-forward "-(v)" (point-max) t))

    ;; Get the column containing observations to predict
    (setq c (current-column))

    ;; Remove last two columns from a previous fitting
    (forward-line 1)
    (end-of-line)
    (org-shiftmetaleft)
    (org-shiftmetaleft)

    ;; Remove the formula from a previous fitting
    (search-forward "#+TBLFM:")
    (beginning-of-line)
    (kill-line)
    (kill-line)

    ;; Put the cursor on the observations column
    (forward-line -1)
    (move-to-column (- c 2))

    ;; And last but not least, compute the best fitting
    (orgtbl-fit model)))

;; Compare the disposable buffer with the reference unittests.org
(goto-char (point-min))
(compare-windows nil)

#+end_src

* Straightforward example

model = ? +?*$1
------(v)
| 1 | 13 | 13.0 | 0.0 |
| 2 | 23 | 23.0 | 0.0 |
| 3 | 33 | 33.0 | 0.0 |
| 4 | 43 | 43.0 | 0.0 |
| 5 | 53 | 53.0 | 0.0 |
#+TBLFM: $3=3. + 10.*$1;%.1f::$4=$3-$2;%.1f

* Simple example

model = ? +?*x +?*y +?*z
--------------(v)
| x | y | z | cost | Best Fit | Fit Diff |
|---+---+---+------+----------+----------|
| 1 | 5 | 1 |   12 |     12.0 |      0.0 |
| 2 | 2 | 5 |   15 |     14.9 |     -0.1 |
| 3 | 9 | 9 |   21 |     21.0 |      0.0 |
| 4 | 1 | 5 |   30 |     30.1 |      0.1 |
| 5 | 8 | 0 |   45 |     45.0 |      0.0 |
#+TBLFM: $5=3.65872496935 + 7.74176542705*$1 + 0.325378013895*$2 - 0.977727829996*$3;%.1f::$6=$5-$4;%.1f

* Same table, but fit a different target column

model = ? +?*x +?*z +?*cost
-----(v)
| x | y | z | cost | Best Fit | Fit Diff |
|---+---+---+------+----------+----------|
| 1 | 5 | 1 |   12 |      4.8 |     -0.2 |
| 2 | 2 | 5 |   15 |      2.3 |      0.3 |
| 3 | 9 | 9 |   21 |      8.9 |     -0.1 |
| 4 | 1 | 5 |   30 |      0.8 |     -0.2 |
| 5 | 8 | 0 |   45 |      8.1 |      0.1 |
#+TBLFM: $5=-11.1966759002 - 23.7132963987*$1 + 2.99515235455*$3 + 3.06325023082*$4;%.1f::$6=$5-$2;%.1f

* Luxurious header

model = ? +?*yme +?*sogd
----------------------(v)
|-------+---------+---------+----------+----------|
|-------+---------+---------+----------+----------|
| yèm:e | so gôöd | Fùb-t:ŭ | Best Fit | Fit Diff |
|   oFf |   --ĥ-- |    (45) |          |          |
|-------+---------+---------+----------+----------|
|     5 |     5.6 |    19.3 |    19.46 |     0.16 |
|     9 |     7.1 |    38.1 |    37.78 |    -0.32 |
|     3 |     1.0 |    14.4 |    14.40 |     0.00 |
|    22 |     7.4 |   102.1 |   102.19 |     0.09 |
|     1 |     9.9 |    -5.1 |    -5.03 |     0.07 |
|-------+---------+---------+----------+----------|
#+TBLFM: $4=0.523420429171 + 4.97911793339*$1 - 1.06392966069*$2;%.2f::$5=$4-$3;%.2f

* Example of portable PCs
Here are some PC with their public prices and technical features

| Brand | Screen | CPU   | OS | Mem Gb | Price |
|-------+--------+-------+----+--------+-------|
| AAA   | 17.3"  | i7 HQ | W  |      4 |   699 |
| BBB   | 17.3"  | i7 HQ | W  |      6 |   749 |
| CCC   | 17.3"  | i5 H  | F  |      4 |   669 |
| DDD   | 17.3"  | i5 U  | W  |      6 |   645 |
| EEE   | 17.3"  | i5 M  | W  |      4 |   669 |
| GGG   | 15.6"  | i7 U  | W  |      8 |   729 |
| HHH   | 15.6"  | i7 U  | W  |      8 |   679 |
| III   | 15.6"  | i7 U  | W  |      8 |   799 |
| JJJ   | 15.6"  | i7 HQ | F  |      4 |   699 |
| KKK   | 15.6"  | i5 U  | W  |     16 |   699 |

Can we predict the price depending on components ?
We put this table in a numerical form as this:

model = ? +?*S173 +?*i7 +?*OS +?*Mem
----------------------------------(v)
| Brand | S173 | i7 | OS | Mem | Price | Best Fit | Fit Diff |
|-------+------+----+----+-----+-------+----------+----------|
| AAA   |    1 |  1 |  1 |   4 |   699 |    721.6 |     22.6 |
| BBB   |    1 |  1 |  1 |   6 |   749 |    731.7 |    -17.3 |
| CCC   |    1 |  0 |  0 |   4 |   669 |    656.9 |    -12.1 |
| DDD   |    1 |  0 |  1 |   6 |   645 |    665.5 |     20.5 |
| EEE   |    1 |  0 |  1 |   4 |   669 |    655.4 |    -13.6 |
| GGG   |    0 |  1 |  1 |   8 |   729 |    729.9 |      0.9 |
| HHH   |    0 |  1 |  1 |   8 |   679 |    729.9 |     50.9 |
| III   |    0 |  1 |  1 |   8 |   799 |    729.9 |    -69.1 |
| JJJ   |    0 |  1 |  0 |   4 |   699 |    711.1 |     12.1 |
| KKK   |    0 |  0 |  1 |  16 |   699 |    704.3 |      5.3 |
#+TBLFM: $7=624.625377644 + 11.9697885194*$2 + 66.1993957702*$3 - 1.52870090624*$4 + 5.07250755283*$5;%.1f::$8=$7-$6;%.1f

The fit is not perfect. Maybe the graphical card should be taken into account.
We see that
- the base price is 625€
- a 17" screen costs 12€ more than a 15" one
- i7 costs an additional 66€ over i5
- W OS or F OS has almost no impact
- 1 additional Gb of memory costs 5€

* Table with header

model = ? +?*a +?*b +?*c
---------------(v)
| a | b |  c |  r s | Best Fit | Fit Diff |
|---+---+----+------+----------+----------|
| 1 | 5 | 10 | 57.7 |    57.70 |     0.00 |
| 2 | 2 | 12 | 30.1 |    29.98 |    -0.12 |
| 3 | 9 | 12 | 99.9 |   100.03 |     0.13 |
| 4 | 1 | 17 | 21.3 |    21.43 |     0.13 |
| 5 | 8 | 17 | 91.6 |    91.47 |    -0.13 |
#+TBLFM: $5=16.7450000002 + 2.99875000004*$1 + 9.57874999999*$2 - 0.993750000022*$3;%.2f::$6=$5-$4;%.2f

* Normalize column names and mix them with dollar forms

model = ? +?*$1 +?*bb +?*dari
-------------------------(v)
| a_a | b & b | daŭri |  r s | Best Fit | Fit Diff |
|-----+-------+-------+------+----------+----------|
|   1 |     5 |    10 | 57.7 |    57.70 |     0.00 |
|   2 |     2 |    12 | 30.1 |    29.98 |    -0.12 |
|   3 |     9 |    12 | 99.9 |   100.03 |     0.13 |
|   4 |     1 |    17 | 21.3 |    21.43 |     0.13 |
|   5 |     8 |    17 | 91.6 |    91.47 |    -0.13 |
#+TBLFM: $5=16.7450000002 + 2.99875000004*$1 + 9.57874999999*$2 - 0.993750000022*$3;%.2f::$6=$5-$4;%.2f

* Non linear model
it depends on a*b

model = ? +?*a + ?*b + ?*a*b +?*c
----------------(v)
| a | b |  c | observ | Best Fit | Fit Diff |
|---+---+----+--------+----------+----------|
| 0 | 1 | 87 |   99.4 |    99.56 |     0.16 |
| 1 | 9 |  8 |  101.8 |   101.76 |    -0.04 |
| 2 | 2 | 28 |   67.5 |    65.06 |    -2.44 |
| 3 | 2 | 87 |  130.6 |   131.66 |     1.06 |
| 4 | 2 | 10 |   60.2 |    62.31 |     2.11 |
| 5 | 6 | 64 |  159.5 |   160.06 |     0.56 |
| 6 | 7 | 61 |  173.9 |   173.53 |    -0.37 |
| 7 | 2 | 69 |  145.2 |   144.16 |    -1.04 |
#+TBLFM: $5=3.36649305617 + 7.69911932103*$1 + 9.22687980815*$2 - 0.0379115297398*$1*$2 + 0.999621843889*$3;%.2f::$6=$5-$4;%.2f

* Table with active header

model = ? +?*a1 +?*b2 +?*c3
-------------------------(v)
| ! | a 1 | b 2 | c 3 | observ | Best Fit | Fit Diff |
|---+-----+-----+-----+--------+----------+----------|
| # |   0 |   1 |  87 | 105.34 |  105.367 |    0.027 |
| # |   1 |   9 |   8 | 105.58 |  105.550 |   -0.030 |
| # |   2 |   2 |  28 |  69.75 |   69.520 |   -0.230 |
| # |   3 |   2 |  87 | 135.46 |  135.548 |    0.088 |
| # |   4 |   2 |  10 |  65.42 |   65.642 |    0.222 |
| # |   5 |   6 |  64 | 162.65 |  162.716 |    0.066 |
| # |   6 |   7 |  61 | 175.79 |  175.785 |   -0.005 |
| # |   7 |   2 |  69 | 145.92 |  145.783 |   -0.137 |
#+TBLFM: $6=9.39808332395 + 7.05658413023*$2 + 9.01098182151*$3 + 0.999518215689*$4;%.3f::$7=$6-$5;%.3f

model = ? +?*b2 +?*c3 +?*observ
------(v)
| ! | a 1 | b 2 | c 3 | observ | Best Fit | Fit Diff |
|---+-----+-----+-----+--------+----------+----------|
| # |   0 |   1 |  87 | 105.34 |     -0.0 |      0.0 |
| # |   1 |   9 |   8 | 105.58 |      1.0 |      0.0 |
| # |   2 |   2 |  28 |  69.75 |      2.0 |      0.0 |
| # |   3 |   2 |  87 | 135.46 |      3.0 |      0.0 |
| # |   4 |   2 |  10 |  65.42 |      4.0 |      0.0 |
| # |   5 |   6 |  64 | 162.65 |      5.0 |      0.0 |
| # |   6 |   7 |  61 | 175.79 |      6.0 |      0.0 |
| # |   7 |   2 |  69 | 145.92 |      7.0 |      0.0 |
#+TBLFM: $6=-1.33158370644 - 1.27686535833*$3 - 0.141632666813*$4 + 0.141702042448*$5;%.1f::$7=$6-$2;%.1f

* More variables than observations
The fit is perfect

model = ? +?*a +?*b +?*c +?*a*b +?*a*c +?*b*c +?*a*a +?*b*b +?*c*c
--------------------(v)
| ! | a | b |  c | observ | Best Fit | Fit Diff |
|---+---+---+----+--------+----------+----------|
| # | 0 | 1 | 87 |   99.4 |    99.40 |     0.00 |
| # | 1 | 9 |  8 |  101.8 |   101.80 |     0.00 |
| # | 2 | 2 | 28 |   67.5 |    67.50 |     0.00 |
| # | 3 | 2 | 87 |  130.6 |   130.60 |     0.00 |
| # | 4 | 2 | 10 |   60.2 |    60.20 |     0.00 |
| # | 5 | 6 | 64 |  159.5 |   159.50 |     0.00 |
| # | 6 | 7 | 61 |  173.9 |   173.90 |     0.00 |
| # | 7 | 2 | 69 |  145.2 |   145.20 |     0.00 |
#+TBLFM: $6=10.4900031258 + 16.991176528*$2 - 13.5614563837*$3 + 1.80261763659*$4 - 1.13804949187*$2*$3 - 0.0453259054771*$2*$4 + 0.122043148842*$3*$4 - 0.557716049364*$2^2 + 2.28265852508*$3^2 - 8.88580969744e-3*$4^2;%.2f::$7=$6-$5;%.2f

* Bigger table

model = ? +?*a +?*b +?*c +?*a*a +?*b*b +?*c*c +?*a*b +?*a*c +?*b*c
--------------------(v)
| ! |  a | b |  c |    obs | Best Fit | Fit Diff |
|---+----+---+----+--------+----------+----------|
| # |  6 | 1 | 16 |  30.25 |   30.191 |   -0.059 |
| # | 14 | 5 | 13 |  42.25 |   42.304 |    0.054 |
| # | 14 | 4 |  9 |  56.25 |   56.070 |   -0.180 |
| # |  9 | 5 | 10 |  61.50 |   61.507 |    0.007 |
| # |  0 | 1 | 15 |  66.75 |   66.757 |    0.007 |
| # |  5 | 3 | 13 |  50.25 |   50.498 |    0.248 |
| # |  2 | 5 | 16 |  63.25 |   63.251 |    0.001 |
| # |  9 | 3 |  7 |  58.50 |   58.513 |    0.013 |
| # |  8 | 2 | 12 |  37.25 |   36.989 |   -0.261 |
| # |  7 | 5 |  9 |  64.25 |   64.511 |    0.261 |
| # |  8 | 4 |  0 |  86.00 |   85.992 |   -0.008 |
| # |  6 | 0 |  2 |  52.00 |   51.941 |   -0.059 |
| # | 10 | 2 |  7 |  50.00 |   50.007 |    0.007 |
| # |  0 | 4 | 19 |  73.00 |   72.992 |   -0.008 |
| # |  5 | 3 | 12 |  52.00 |   52.005 |    0.005 |
| # |  6 | 4 |  0 |  78.00 |   78.007 |    0.007 |
| # |  6 | 5 | 19 |  44.50 |   44.176 |   -0.324 |
| # | 14 | 5 |  9 |  66.25 |   66.311 |    0.061 |
| # |  6 | 7 | 19 |  51.00 |   51.141 |    0.141 |
| # | 14 | 1 | 19 | -37.75 |  -37.728 |    0.022 |
| # |  8 | 1 | 17 |  14.25 |   14.688 |    0.438 |
| # |  6 | 1 | 10 |  42.50 |   42.229 |   -0.271 |
| # |  6 | 7 |  2 |  85.40 |   85.247 |   -0.153 |
| # | 14 | 6 |  5 | 100.00 |  100.036 |    0.036 |
| # |  2 | 0 |  7 |  52.00 |   51.995 |   -0.005 |
| # | 11 | 6 | 10 |  68.50 |   68.505 |    0.005 |
| # | 13 | 3 | 16 |   8.00 |    8.033 |    0.033 |
| # | 10 | 7 |  2 | 106.25 |  106.223 |   -0.027 |
| # | 10 | 4 | 15 |  34.00 |   33.993 |   -0.007 |
| # |  4 | 0 |  1 |  53.00 |   52.955 |   -0.045 |
| # | 13 | 0 | 12 |  -3.00 |   -2.987 |    0.013 |
| # |  0 | 2 |  7 |  60.00 |   60.093 |    0.093 |
| # |  8 | 4 |  7 |  65.00 |   65.015 |    0.015 |
| # |  3 | 2 | 17 |  52.00 |   51.961 |   -0.039 |
| # | 10 | 1 |  1 |  65.00 |   65.209 |    0.209 |
| # | 14 | 2 | 11 |  22.25 |   22.067 |   -0.183 |
| # |  9 | 5 | 18 |  33.50 |   33.447 |   -0.053 |
| # |  7 | 5 | 13 |  54.50 |   54.489 |   -0.011 |
| # | 11 | 3 | 13 |  31.00 |   31.017 |    0.017 |
| # |  1 | 4 | 16 |  66.00 |   66.019 |    0.019 |
| # |  5 | 2 | 17 |  40.00 |   39.949 |   -0.051 |
| # |  8 | 4 |  9 |  59.00 |   59.013 |    0.013 |
| # |  6 | 3 |  7 |  59.25 |   59.267 |    0.017 |
| # | 14 | 6 |  7 |  88.00 |   88.042 |    0.042 |
| # |  3 | 2 | 17 |  52.00 |   51.961 |   -0.039 |
#+TBLFM: $6=50.0286486413 + 0.97383137796*$2 + 2.03969765393*$3 + 1.0044190737*$4 + 1.55554750813e-3*$2^2 - 0.253663691799*$3^2 - 5.21686927352e-4*$4^2 + 0.749146746167*$2*$3 - 0.499461191284*$2*$4 - 4.25906301855e-4*$3*$4;%.3f::$7=$6-$5;%.3f

* Apples & bananas

We need to estimate the average weight of apples, bananas, and
strawberries.  But we only have weights for some packages containing a
mix of such fruits.

The weight of a package is the weight of apples, bananas, and
strawberries composing the package, plus the packaging itself.  The
packagings are all the same.

Let us store data in an Org Mode table, one row per observation.  Each
row counts the number of fruits in a pack, plus the weight of the pack
(in grams).

model = ? +?*apples +?*bananas +?*strawberries
---------------------------------------(v)
| apples | bananas | strawberries | total weight | Best Fit | Fit Diff |
|--------+---------+--------------+--------------+----------+----------|
|      8 |       4 |           48 |         2928 |   2926.4 |     -1.6 |
|     11 |       8 |           21 |         3561 |   3561.9 |      0.9 |
|      9 |       6 |           32 |         3140 |   3146.7 |      6.7 |
|      8 |       3 |           47 |         2737 |   2741.0 |      4.0 |
|     10 |       1 |           27 |         2349 |   2339.7 |     -9.3 |
|     10 |       0 |           11 |         1927 |   1929.1 |      2.1 |
|      7 |       6 |           10 |         2581 |   2577.0 |     -4.0 |
|      5 |       1 |           11 |         1499 |   1500.6 |      1.6 |
|      1 |       8 |           13 |         2245 |   2244.1 |     -0.9 |
|      9 |       5 |           42 |         3128 |   3126.5 |     -1.5 |
|      7 |       6 |           26 |         2818 |   2817.1 |     -0.9 |
|      1 |       2 |           40 |         1630 |   1627.1 |     -2.9 |
|      9 |       6 |           33 |         3160 |   3161.7 |      1.7 |
|      5 |       8 |           32 |         3009 |   3008.3 |     -0.7 |
|      3 |       0 |           18 |         1191 |   1195.8 |      4.8 |
#+TBLFM: $5=566.276919769 + 119.776891962*$1 + 170.361128214*$2 + 15.0090368021*$3;%.1f::$6=$5-$4;%.1f

The fit is quite good. It should be interpreted as:
- weight of the packaging  = 566.276919769 grams
- weight of one apple      = 119.776891962 grams
- weight of one banana     = 170.361128214 grams
- weight of one strawberry =  15.009036802 grams

* Example: revenue of a shop

A shop gets changing revenues.  Less sells are performed when weather
is rainy.  More sells are performed on Saturdays.  To be sure,
observations are recorded over a few days.  Here they are, one row per
day:

model = ? +?*Saturday +?*Rainy +?*Sunny +?*Winter
----------------------------------------(v)
| Saturday | Rainy | Sunny | Winter | Revenue | Best Fit | Fit Diff |
|----------+-------+-------+--------+---------+----------+----------|
|        1 |     1 |     0 |      0 |   19674 |  19822.2 |    148.2 |
|        0 |     1 |     0 |      0 |   13972 |  13913.9 |    -58.1 |
|        0 |     1 |     0 |      0 |   13845 |  13913.9 |     68.9 |
|        0 |     0 |     0 |      0 |   15997 |  15996.7 |     -0.3 |
|        0 |     0 |     1 |      0 |   15253 |  15254.1 |      1.1 |
|        0 |     0 |     1 |      0 |   15466 |  15254.1 |   -211.9 |
|        1 |     0 |     0 |      0 |   22128 |  21905.0 |   -223.0 |
|        0 |     0 |     0 |      0 |   16092 |  15996.7 |    -95.3 |
|        0 |     0 |     0 |      0 |   15764 |  15996.7 |    232.7 |
|        0 |     1 |     0 |      0 |   14116 |  13913.9 |   -202.1 |
|        0 |     1 |     0 |      0 |   13817 |  13913.9 |     96.9 |
|        0 |     0 |     0 |      0 |   15754 |  15996.7 |    242.7 |
|        1 |     0 |     1 |      1 |   20593 |  20667.8 |     74.8 |
|        0 |     0 |     1 |      1 |   14592 |  14759.5 |    167.5 |
|        0 |     0 |     1 |      1 |   14791 |  14759.5 |    -31.5 |
|        0 |     0 |     0 |      1 |   15653 |  15502.0 |   -151.0 |
|        0 |     1 |     0 |      1 |   13473 |  13419.2 |    -53.8 |
|        0 |     0 |     0 |      1 |   15508 |  15502.0 |     -6.0 |
#+TBLFM: $6=15996.7226519 + 5908.30497238*$1 - 2082.82651934*$2 - 742.574585636*$3 - 494.681767955*$4;%.1f::$7=$6-$5;%.1f

Note that a day may be neither rainy nor sunny.  Observations are not
very precise: for instance, a day may be rainy only in the morning,
but it is recorded as "1".  Winter season is also quite coarse, as it
is either 1 or 0, nothing in between.

Not bad: revenue is predicted within 1% error.

The formula is interesting.  Let us look at it in detail:

$6=
  15996.7226519
  + 5908.30497238 $1
  - 2082.82651934 $2
  - 742.574585636 $3
  - 494.681767955 $4

We get what we were looking for: the influence of each factor on the
revenue.  We have:
- a base revenue of 15997
- an additional 5908 revenue on Saturdays
- a big negative impact of rain: 2083 lost in revenue
- sunny days lessen revenue by 743 too
- in winter 495 is lost every day.

The surprise comes from the bad impact of rain *and* sun.  Actually,
people are more eager to shop on cloudy days.

Even though the fit is not perfect, it gives figures which can help
steering the activity.  More sales persons are required on Saturday,
and less on rainy days, and we know approximately how many:
- 5908 / 15997 = 37% more on Saturdays
- 2083 / 15997 = 13% less on rainy days
- etc.

This kind of analysis can be further enhanced.  More observations will
smooth statistical errors.  More criterias will better explain the
revenue.  For instance, adding a column about movies blockbusters may
give better fit with less differences (people go to movies theaters
instead of shopping).

* Big table

model = ? +?*a +?*b +?*c +?*d +?*e
----------------------------(v)
|  a |   b | c |  d |  e |       r | Best Fit | Fit Diff |
|----+-----+---+----+----+---------+----------+----------|
| 81 | 190 | 7 | 26 | 56 |  801.74 |  801.598 |   -0.142 |
| 35 | 176 | 4 | 33 | 79 |  663.89 |  663.515 |   -0.375 |
| 36 | 155 | 3 | 35 | 96 |  630.88 |  630.498 |   -0.382 |
| 61 | 122 | 5 | 39 | 76 |  535.66 |  535.538 |   -0.122 |
| 98 | 116 | 0 | 29 | 98 |  622.40 |  622.561 |    0.161 |
| 18 | 112 | 6 | 40 | 88 |  466.55 |  466.474 |   -0.076 |
| 53 | 111 | 8 | 45 | 54 |  441.94 |  441.543 |   -0.397 |
| 65 | 142 | 5 | 29 | 84 |  667.40 |  667.544 |    0.144 |
| 91 | 138 | 1 |  4 | 84 |  747.65 |  747.570 |   -0.080 |
| 30 | 164 | 7 | 25 | 55 |  622.18 |  622.526 |    0.346 |
| 36 | 140 | 3 | 12 | 60 |  569.47 |  569.518 |    0.048 |
| 29 | 177 | 1 | 22 | 98 |  710.81 |  710.491 |   -0.319 |
| 80 | 139 | 4 | 20 | 74 |  679.90 |  679.567 |   -0.333 |
|  2 | 116 | 8 | 26 | 97 |  559.10 |  559.453 |    0.353 |
| 93 | 113 | 6 |  1 | 76 |  739.69 |  739.580 |   -0.110 |
| 82 | 181 | 3 | 40 | 96 |  780.96 |  780.564 |   -0.396 |
| 24 | 134 | 9 | 31 | 52 |  517.97 |  517.516 |   -0.454 |
| 58 | 198 | 1 | 14 | 51 |  722.89 |  722.563 |   -0.327 |
| 58 | 137 | 6 | 29 | 53 |  560.23 |  560.554 |    0.324 |
| 87 | 140 | 7 | 37 | 93 |  730.81 |  730.569 |   -0.241 |
| 84 | 189 | 2 | 19 | 66 |  787.10 |  787.587 |    0.487 |
| 70 | 157 | 0 | 16 | 70 |  657.89 |  657.554 |   -0.336 |
|  1 | 132 | 3 |  5 | 97 |  614.22 |  614.447 |    0.227 |
| 23 | 153 | 7 |  3 | 80 |  738.34 |  738.499 |    0.159 |
|  1 | 178 | 0 | 49 | 71 |  453.55 |  453.469 |   -0.081 |
| 14 | 109 | 1 | 26 | 93 |  445.47 |  445.456 |   -0.014 |
| 73 | 108 | 3 | 45 | 99 |  532.04 |  532.531 |    0.491 |
| 78 | 141 | 9 | 21 | 85 |  785.42 |  785.567 |    0.147 |
| 82 | 158 | 4 |  0 | 98 |  892.32 |  892.560 |    0.240 |
| 14 | 169 | 8 | 21 | 58 |  645.62 |  645.507 |   -0.113 |
| 91 | 144 | 7 | 31 | 63 |  684.19 |  684.594 |    0.404 |
| 44 | 126 | 2 | 33 | 64 |  456.51 |  456.519 |    0.009 |
| 83 | 154 | 1 | 42 | 73 |  594.24 |  594.569 |    0.329 |
| 51 | 198 | 5 | 18 | 67 |  800.84 |  800.551 |   -0.289 |
| 59 | 137 | 6 | 21 | 96 |  723.37 |  723.529 |    0.159 |
| 28 | 154 | 2 | 33 | 89 |  583.31 |  583.490 |    0.180 |
| 31 | 160 | 4 | 19 | 74 |  648.68 |  648.509 |   -0.171 |
| 88 | 194 | 3 | 21 | 54 |  781.84 |  781.603 |   -0.237 |
| 55 | 133 | 5 | 30 | 54 |  526.93 |  526.547 |   -0.383 |
| 91 | 156 | 0 | 21 | 87 |  727.37 |  727.570 |    0.200 |
| 78 | 173 | 4 | 44 | 93 |  738.84 |  738.561 |   -0.279 |
| 25 | 134 | 1 | 17 | 59 |  476.54 |  476.499 |   -0.041 |
| 12 | 144 | 6 | 28 | 74 |  556.71 |  556.484 |   -0.226 |
| 86 | 145 | 7 | 11 | 93 |  847.70 |  847.570 |   -0.130 |
| 47 | 178 | 9 | 48 | 88 |  735.27 |  735.534 |    0.264 |
| 67 | 175 | 5 | 33 | 51 |  655.96 |  655.575 |   -0.385 |
| 59 | 166 | 2 | 13 | 99 |  791.40 |  791.528 |    0.128 |
| 79 | 184 | 9 | 44 | 99 |  866.72 |  866.570 |   -0.150 |
| 26 | 197 | 0 | 31 | 62 |  605.13 |  605.512 |    0.382 |
| 34 | 178 | 7 | 29 | 54 |  653.41 |  653.536 |    0.126 |
| 45 | 189 | 7 | 18 | 95 |  875.28 |  875.527 |    0.247 |
| 79 | 108 | 0 | 44 | 91 |  479.83 |  479.538 |   -0.292 |
| 24 | 105 | 4 | 42 | 74 |  377.02 |  377.485 |    0.465 |
| 98 | 195 | 2 | 23 | 64 |  811.20 |  811.608 |    0.408 |
|  7 | 107 | 5 |  6 | 61 |  469.02 |  469.475 |    0.455 |
| 57 | 107 | 1 | 37 | 98 |  496.73 |  496.507 |   -0.223 |
| 63 | 157 | 1 | 11 | 63 |  657.35 |  657.552 |    0.202 |
| 99 | 104 | 0 |  9 | 89 |  641.89 |  641.566 |   -0.324 |
| 87 | 121 | 5 | 27 | 91 |  677.15 |  677.562 |    0.412 |
| 37 | 133 | 6 | 14 | 87 |  668.84 |  668.505 |   -0.335 |
| 39 | 100 | 1 | 28 | 60 |  361.05 |  361.507 |    0.457 |
| 35 | 138 | 0 | 34 | 66 |  446.21 |  446.506 |    0.296 |
| 86 | 143 | 1 | 25 | 98 |  710.12 |  710.555 |    0.435 |
|  2 | 187 | 4 | 30 | 54 |  567.46 |  567.491 |    0.031 |
|  4 | 171 | 4 | 33 | 84 |  601.88 |  601.471 |   -0.409 |
| 74 | 157 | 7 | 15 | 72 |  780.18 |  780.571 |    0.391 |
| 12 | 130 | 4 |  5 | 84 |  606.53 |  606.471 |   -0.059 |
| 77 | 101 | 2 |  0 | 57 |  558.91 |  558.561 |   -0.349 |
| 20 | 172 | 2 |  1 | 64 |  674.80 |  674.502 |   -0.298 |
| 15 | 157 | 1 | 28 | 58 |  478.68 |  478.492 |   -0.188 |
| 93 | 100 | 7 |  8 | 62 |  645.89 |  645.587 |   -0.303 |
| 89 | 158 | 4 | 20 | 59 |  709.54 |  709.593 |    0.053 |
| 86 | 168 | 5 | 32 | 93 |  802.30 |  802.572 |    0.272 |
| 83 | 107 | 2 |  8 | 95 |  670.15 |  670.546 |    0.396 |
| 23 | 151 | 3 | 19 | 77 |  599.82 |  599.493 |   -0.327 |
| 39 | 167 | 5 |  6 | 84 |  782.22 |  782.517 |    0.297 |
| 36 | 157 | 0 | 24 | 93 |  626.17 |  626.496 |    0.326 |
|  4 | 126 | 3 | 43 | 79 |  396.38 |  396.459 |    0.079 |
|  2 | 104 | 5 |  3 | 75 |  504.82 |  504.459 |   -0.361 |
| 41 | 190 | 9 | 36 | 51 |  696.39 |  696.553 |    0.163 |
| 85 | 137 | 3 | 41 | 88 |  626.72 |  626.561 |   -0.159 |
| 19 | 133 | 7 | 39 | 87 |  547.62 |  547.483 |   -0.137 |
| 66 | 112 | 1 |  4 | 96 |  655.23 |  655.523 |    0.293 |
| 16 | 138 | 9 |  2 | 76 |  701.97 |  701.493 |   -0.477 |
| 57 | 130 | 2 | 24 | 50 |  488.31 |  488.546 |    0.236 |
| 67 | 165 | 0 | 21 | 97 |  736.80 |  736.535 |   -0.265 |
| 86 | 183 | 5 | 13 | 72 |  860.06 |  860.590 |    0.530 |
| 40 | 160 | 1 | 41 | 76 |  539.23 |  539.513 |    0.283 |
| 91 | 189 | 9 | 39 | 89 |  895.86 |  895.593 |   -0.267 |
| 43 | 175 | 5 | 49 | 50 |  540.38 |  540.545 |    0.165 |
| 82 | 149 | 5 | 28 | 87 |  735.79 |  735.566 |   -0.224 |
| 98 | 115 | 5 | 47 | 81 |  571.40 |  571.580 |    0.180 |
| 32 | 170 | 9 | 31 | 50 |  635.15 |  635.537 |    0.387 |
| 13 | 187 | 5 | 42 | 79 |  631.31 |  631.491 |    0.181 |
| 10 | 167 | 0 |  9 | 76 |  613.06 |  613.476 |    0.416 |
| 82 | 169 | 9 | 43 | 67 |  735.47 |  735.590 |    0.120 |
| 81 | 103 | 7 | 46 | 86 |  550.96 |  550.556 |   -0.404 |
| 28 | 105 | 5 | 36 | 87 |  463.33 |  463.484 |    0.154 |
| 29 | 156 | 9 | 27 | 96 |  741.47 |  741.501 |    0.031 |
| 77 | 192 | 5 | 20 | 70 |  835.89 |  835.581 |   -0.309 |
| 46 | 102 | 1 | 49 | 66 |  315.69 |  315.512 |   -0.178 |
|  0 | 141 | 0 | 41 | 62 |  345.78 |  345.464 |   -0.316 |
| 57 | 174 | 5 |  8 | 90 |  849.60 |  849.539 |   -0.061 |
| 38 | 158 | 7 | 34 | 87 |  680.41 |  680.515 |    0.105 |
| 66 | 104 | 6 |  8 | 89 |  669.88 |  669.534 |   -0.346 |
| 71 | 145 | 6 | 13 | 92 |  791.81 |  791.549 |   -0.261 |
| 12 | 100 | 0 | 38 | 65 |  267.83 |  267.466 |   -0.364 |
| 32 | 139 | 8 | 44 | 98 |  619.54 |  619.496 |   -0.044 |
| 15 | 145 | 5 | 13 | 77 |  619.95 |  619.485 |   -0.465 |
| 13 | 195 | 9 | 35 | 58 |  680.60 |  680.514 |   -0.086 |
| 62 | 134 | 4 |  3 | 57 |  645.01 |  645.554 |    0.544 |
| 19 | 127 | 4 | 25 | 81 |  522.98 |  522.480 |   -0.500 |
| 79 | 105 | 4 | 42 | 67 |  466.96 |  466.560 |   -0.400 |
| 27 | 112 | 5 | 19 | 58 |  463.01 |  463.503 |    0.493 |
| 60 | 176 | 8 | 24 | 72 |  788.05 |  788.559 |    0.509 |
| 28 | 119 | 2 | 13 | 70 |  501.28 |  501.494 |    0.214 |
| 84 | 168 | 5 | 18 | 96 |  863.40 |  863.568 |    0.168 |
| 22 | 161 | 8 | 28 | 97 |  726.53 |  726.490 |   -0.040 |
| 95 | 162 | 8 | 29 | 67 |  781.50 |  781.604 |    0.104 |
| 38 | 154 | 1 | 25 | 87 |  614.13 |  614.503 |    0.373 |
|  8 | 134 | 3 | 46 | 98 |  473.62 |  473.455 |   -0.165 |
| 41 | 141 | 3 | 28 | 66 |  536.71 |  536.520 |   -0.190 |
| 25 | 130 | 9 | 44 | 87 |  560.89 |  560.494 |   -0.396 |
| 15 | 193 | 6 | 24 | 64 |  695.58 |  695.507 |   -0.073 |
| 68 | 184 | 2 | 39 | 73 |  681.77 |  681.560 |   -0.210 |
| 25 | 158 | 3 |  1 | 83 |  714.29 |  714.494 |    0.204 |
| 82 | 116 | 3 | 26 | 93 |  632.81 |  632.549 |   -0.261 |
| 70 | 132 | 1 | 24 | 88 |  619.85 |  619.538 |   -0.312 |
| 27 | 173 | 9 |  7 | 59 |  757.11 |  757.527 |    0.417 |
| 40 | 198 | 4 | 23 | 56 |  710.91 |  710.542 |   -0.368 |
|  6 | 128 | 6 | 28 | 51 |  427.63 |  427.486 |   -0.144 |
| 54 | 137 | 3 |  4 | 77 |  679.98 |  679.530 |   -0.450 |
| 39 | 107 | 5 |  1 | 53 |  529.65 |  529.521 |   -0.129 |
| 54 | 134 | 0 | 26 | 91 |  579.71 |  579.514 |   -0.196 |
| 46 | 149 | 8 |  7 | 95 |  816.26 |  816.520 |    0.260 |
| 97 | 189 | 8 |  2 | 76 | 1001.99 | 1001.609 |   -0.381 |
| 76 | 193 | 0 | 36 | 95 |  772.67 |  772.555 |   -0.115 |
| 31 | 132 | 5 | 14 | 69 |  584.67 |  584.507 |   -0.163 |
| 83 | 176 | 1 | 49 | 55 |  578.82 |  578.586 |   -0.234 |
| 90 | 147 | 9 | 33 | 90 |  794.81 |  794.581 |   -0.229 |
| 44 | 109 | 6 | 13 | 97 |  644.09 |  644.502 |    0.412 |
| 25 | 150 | 1 | 38 | 58 |  437.74 |  437.503 |   -0.237 |
| 37 | 170 | 8 |  9 | 86 |  826.80 |  826.520 |   -0.280 |
| 88 | 166 | 4 | 34 | 99 |  795.72 |  795.568 |   -0.152 |
| 50 | 175 | 6 | 14 | 83 |  808.52 |  808.536 |    0.016 |
| 36 | 143 | 5 | 32 | 71 |  561.17 |  561.514 |    0.344 |
| 89 | 141 | 0 | 26 | 59 |  574.34 |  574.581 |    0.241 |
| 71 | 136 | 7 | 42 | 57 |  558.65 |  558.570 |   -0.080 |
| 92 | 167 | 0 | 28 | 55 |  638.60 |  638.594 |   -0.006 |
| 42 | 142 | 1 | 15 | 54 |  527.35 |  527.526 |    0.176 |
| 97 | 146 | 3 | 27 | 70 |  679.77 |  679.591 |   -0.179 |
| 14 | 187 | 7 |  9 | 69 |  765.45 |  765.504 |    0.054 |
|  8 | 181 | 0 | 35 | 57 |  490.33 |  490.488 |    0.158 |
| 24 | 175 | 0 | 32 | 56 |  513.23 |  513.508 |    0.278 |
| 31 | 197 | 5 | 30 | 77 |  739.49 |  739.519 |    0.029 |
|  4 | 159 | 7 | 40 | 83 |  579.35 |  579.473 |    0.123 |
| 75 | 139 | 1 | 44 | 95 |  591.59 |  591.541 |   -0.049 |
| 91 | 172 | 8 | 36 | 54 |  736.82 |  736.609 |   -0.211 |
| 28 | 146 | 3 | 31 | 55 |  480.70 |  480.511 |   -0.189 |
| 54 | 196 | 2 | 34 | 98 |  784.02 |  784.529 |    0.509 |
| 77 | 106 | 6 |  0 | 53 |  621.58 |  621.572 |   -0.008 |
| 19 | 130 | 7 |  8 | 90 |  671.25 |  671.482 |    0.232 |
| 50 | 162 | 7 | 48 | 79 |  636.59 |  636.536 |   -0.054 |
| 39 | 108 | 1 | 10 | 85 |  532.65 |  532.494 |   -0.156 |
| 14 | 158 | 1 | 45 | 63 |  426.60 |  426.487 |   -0.113 |
| 38 | 105 | 6 | 13 | 98 |  623.14 |  623.492 |    0.352 |
| 22 | 119 | 1 |  7 | 58 |  462.70 |  462.492 |   -0.208 |
| 50 | 144 | 3 | 11 | 97 |  724.68 |  724.514 |   -0.166 |
|  3 | 121 | 4 | 40 | 73 |  388.13 |  388.463 |    0.333 |
| 82 | 102 | 9 | 24 | 92 |  685.51 |  685.557 |    0.047 |
| 88 | 106 | 7 | 30 | 89 |  646.85 |  646.564 |   -0.286 |
| 92 | 171 | 9 | 21 | 63 |  837.36 |  837.607 |    0.247 |
| 19 | 187 | 6 | 37 | 60 |  621.43 |  621.513 |    0.083 |
| 31 | 135 | 3 | 38 | 95 |  545.12 |  545.487 |    0.367 |
| 99 | 107 | 6 | 23 | 80 |  657.19 |  657.583 |    0.393 |
| 56 | 189 | 7 | 36 | 51 |  693.20 |  693.569 |    0.369 |
| 21 | 168 | 5 | 33 | 97 |  680.92 |  680.485 |   -0.435 |
| 13 | 115 | 2 | 25 | 70 |  411.32 |  411.473 |    0.153 |
| 75 | 160 | 9 | 12 | 66 |  815.91 |  815.580 |   -0.330 |
| 63 | 138 | 7 | 26 | 51 |  594.67 |  594.564 |   -0.106 |
| 43 | 136 | 8 |  8 | 87 |  743.46 |  743.518 |    0.058 |
| 77 | 151 | 4 |  7 | 69 |  746.74 |  746.570 |   -0.170 |
| 88 | 186 | 7 | 11 | 84 |  947.75 |  947.589 |   -0.161 |
|  0 | 114 | 8 | 48 | 90 |  440.28 |  440.453 |    0.173 |
| 91 | 161 | 4 | 18 | 64 |  745.91 |  745.593 |   -0.317 |
| 61 | 116 | 4 |  6 | 78 |  640.93 |  640.534 |   -0.396 |
| 46 | 101 | 9 |  5 | 67 |  611.53 |  611.527 |   -0.003 |
| 93 | 178 | 1 | 46 | 83 |  700.21 |  700.582 |    0.372 |
| 40 | 133 | 7 | 32 | 77 |  587.89 |  587.517 |   -0.373 |
| 79 | 111 | 0 | 43 | 88 |  483.05 |  483.541 |    0.491 |
| 16 | 167 | 1 | 27 | 94 |  622.96 |  622.473 |   -0.487 |
| 98 | 198 | 6 | 37 | 72 |  848.59 |  848.610 |    0.020 |
| 84 | 181 | 9 | 15 | 72 |  902.42 |  902.594 |    0.174 |
| 60 | 170 | 3 | 45 | 67 |  596.53 |  596.551 |    0.021 |
| 35 | 115 | 9 |  5 | 63 |  619.36 |  619.519 |    0.159 |
| 55 | 132 | 9 | 33 | 69 |  616.03 |  616.545 |    0.515 |
| 32 | 101 | 4 |  3 | 59 |  492.30 |  492.505 |    0.205 |
| 95 | 136 | 5 |  2 | 76 |  793.31 |  793.587 |    0.277 |
|  4 | 111 | 8 | 48 | 69 |  376.32 |  376.471 |    0.151 |
| 18 | 160 | 7 |  7 | 52 |  649.27 |  649.512 |    0.242 |
| 47 | 174 | 4 |  8 | 75 |  769.88 |  769.533 |   -0.347 |
| 74 | 103 | 7 | 49 | 80 |  506.74 |  506.550 |   -0.190 |
| 53 | 162 | 1 | 23 | 54 |  577.99 |  577.545 |   -0.445 |
| 33 | 124 | 6 | 44 | 82 |  498.38 |  498.500 |    0.120 |
| 33 | 137 | 1 | 46 | 53 |  367.28 |  367.512 |    0.232 |
| 83 | 161 | 2 | 43 | 92 |  683.29 |  683.561 |    0.271 |
| 56 | 142 | 3 | 33 | 53 |  510.48 |  510.548 |    0.068 |
|  9 | 125 | 4 | 38 | 59 |  378.49 |  378.480 |   -0.010 |
#+TBLFM: $7=2.00129080599*$1 - 99.5335835577 + 3.0002668215*$2 + 15.0018239589*$3 - 4.00003659322*$4 + 2.99937221779*$5;%.3f::$8=$7-$6;%.3f

The resulting formula contains numerical values quite close from integer.  Probably the model should be rounded:
: 2*$1 - 99.5 + 3*$2 + 15*$3 - 4*$4 + 3*$5

* Example population employee rate

City vs. country employment rate in the population is given in the following table. Female employees are marked with 1 in the 'F' column.

Can this rate be predicted?

model = ? +?*urban +?*F
----------------(v)
| urban | F |  rate | Best Fit | Fit Diff |
|-------+---+-------+----------+----------|
|     1 | 1 | 0.390 |   0.3589 |  -0.0311 |
|     1 | 0 | 0.438 |   0.4513 |   0.0133 |
|     1 | 1 | 0.341 |   0.3589 |   0.0179 |
|     0 | 0 | 0.457 |   0.4437 |  -0.0133 |
|     0 | 1 | 0.338 |   0.3513 |   0.0133 |
#+TBLFM: $4=0.443714285714 + 7.57142857143e-3*$1 - 0.0924285714286*$2;%.4f::$5=$4-$3;%.4f

We see that:
- average employment rate is 0.444
- urban employment is slightly higher: 0.00757
- female employment is lower than average by 0.092

* Holes
This problem can be solved
- by pre-school children in five minutes
- by data scientists in an hour
- and by people with higher education…

How long will you need to solve it ?

8809 = 6
7111 = 0
2172 = 0
6666 = 4
1111 = 0
3213 = 0
7662 = 2
9313 = 1
0000 = 4
2222 = 0
3333 = 0
5555 = 0
8193 = 3
8096 = 5
1012 = 1
7777 = 0
9999 = 4
7756 = 1
6855 = 3
9881 = 5
5531 = 0
2581 = ???

Let us put it in the form of an Org table.
For exmaple, column 'a3' tells how many '3' digits aare there in the observation.
Note that there is no 'a4' column.
We want to predict column 'n'.

model = ?*a0 +?*a1 +?*a2 +?*a3 +?*a5 +?*a6 +?*a7 +?*a8 +?*a9
----------------------------------------------(v)
| a0 | a1 | a2 | a3 | a5 | a6 | a7 | a8 | a9 | n | Best Fit | Fit Diff |
|----+----+----+----+----+----+----+----+----+---+----------+----------|
|  1 |  0 |  0 |  0 |  0 |  0 |  0 |  2 |  1 | 6 |      6.0 |      0.0 |
|  0 |  3 |  0 |  0 |  0 |  0 |  1 |  0 |  0 | 0 |      0.0 |      0.0 |
|  0 |  1 |  2 |  0 |  0 |  0 |  1 |  0 |  0 | 0 |     -0.0 |      0.0 |
|  0 |  0 |  0 |  0 |  0 |  4 |  0 |  0 |  0 | 4 |      4.0 |      0.0 |
|  0 |  4 |  0 |  0 |  0 |  0 |  0 |  0 |  0 | 0 |      0.0 |      0.0 |
|  0 |  1 |  1 |  2 |  0 |  0 |  0 |  0 |  0 | 0 |     -0.0 |      0.0 |
|  0 |  0 |  1 |  0 |  0 |  2 |  1 |  0 |  0 | 2 |      2.0 |      0.0 |
|  0 |  1 |  0 |  2 |  0 |  0 |  0 |  0 |  1 | 1 |      1.0 |      0.0 |
|  4 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |  0 | 4 |      4.0 |      0.0 |
|  0 |  0 |  4 |  0 |  0 |  0 |  0 |  0 |  0 | 0 |     -0.0 |      0.0 |
|  0 |  0 |  0 |  4 |  0 |  0 |  0 |  0 |  0 | 0 |      0.0 |      0.0 |
|  0 |  0 |  0 |  0 |  4 |  0 |  0 |  0 |  0 | 0 |      0.0 |      0.0 |
|  0 |  1 |  0 |  1 |  0 |  0 |  0 |  1 |  1 | 3 |      3.0 |      0.0 |
|  1 |  2 |  1 |  0 |  0 |  0 |  0 |  0 |  0 | 1 |      1.0 |      0.0 |
|  0 |  0 |  0 |  0 |  0 |  0 |  4 |  0 |  0 | 0 |      0.0 |      0.0 |
|  0 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |  4 | 4 |      4.0 |      0.0 |
#+TBLFM: $11=$1 - 9.90310521096e-15*$3 + 4.13796369376e-15*$4 + $6 + 7.74810196662e-15*$7 + 2.*$8 + $9;%.1f::$12=$11-$10;%.1f

Prediction is perfect. We can round the formula:
: $1 + $6 + 2.*$8 + $9

- $1 is a0, digit 0, which counts for 1
- $6 is a6, digit 6, which counts for 1
- $8 is a8, digit 8, which counts for 2
- $9 is a9, digit 9, which counts for 1

So, orgtbl-fit discovered that only digits 0, 6, 8, 9 count. Other
digits can be discarded. Those are digits with "holes"
So the answer is 2581 = 2, because there a 2 holes.

* Best teacher?
model = ? +?*theo +?*theo^2 +?*duration +?* duration^2 +?*theo*duration
-------------------------(v)
|  theo | duration | quizzresult | Best Fit | Fit Diff |
|-------+----------+-------------+----------+----------|
| 0.781 |     18.0 |        30.3 |    31.42 |     1.12 |
| 0.615 |     38.3 |         5.2 |     5.40 |     0.20 |
| 0.601 |      5.2 |        52.5 |    51.29 |    -1.21 |
| 0.176 |      4.4 |        60.4 |    59.52 |    -0.88 |
| 0.428 |     40.9 |        10.5 |    11.33 |     0.83 |
| 0.255 |     12.2 |        66.2 |    67.27 |     1.07 |
| 0.784 |     12.6 |        34.2 |    34.28 |     0.08 |
| 0.468 |      5.4 |        58.1 |    59.60 |     1.50 |
| 0.475 |     37.6 |        19.8 |    20.20 |     0.40 |
| 0.605 |     22.5 |        47.5 |    46.21 |    -1.29 |
| 0.319 |     24.8 |        58.7 |    58.57 |    -0.13 |
| 0.713 |     30.1 |        19.2 |    19.09 |    -0.11 |
| 0.596 |     36.0 |        15.6 |    15.26 |    -0.34 |
| 0.659 |     21.8 |        42.5 |    41.81 |    -0.69 |
| 0.731 |     19.6 |        36.2 |    36.27 |     0.07 |
| 0.309 |     44.0 |         4.9 |     4.27 |    -0.63 |
#+TBLFM: $4=41.310831661 + 86.6227413961*$1 - 134.496123584*$1^2 + 2.04949509715*$2 - 0.067672358144*$2^2 - 0.744700713305*$2*$1;%.2f::$5=$4-$3;%.2f
